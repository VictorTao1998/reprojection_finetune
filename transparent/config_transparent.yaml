# Config files for remote training on transparent dataset

# Directories
DIR:
  DATASET: '/cephfs/datasets/iccv_pnp/messy-table-dataset/transparent/training/'  #  directory of your training dataset

# Split files
SPLIT:
  TRAIN: '/cephfs/datasets/iccv_pnp/messy-table-dataset/transparent/training_lists/train.txt'  # training lists of your training set
  VAL: '/cephfs/datasets/iccv_pnp/messy-table-dataset/transparent/training_lists/val.txt'  # training lists of your validation set
  TEST: '/cephfs/datasets/iccv_pnp/messy-table-dataset/transparent/training_lists/test.txt'  # training lists of your validation set
  LEFT: '0128_irL_kuafu_half.png'
  LEFT_NO_IR: '0128_irL_kuafu_half_no_ir.png'
  RIGHT: '0128_irR_kuafu_half.png'
  RIGHT_NO_IR: '0128_irR_kuafu_half_no_ir.png'
  DEPTHL: 'depthL.png'
  DEPTHR: 'depthR.png'
  META: 'meta.pkl'

# Solver args
SOLVER:
  LR_CASCADE: 0.0002                         # base learning rate for cascade
  LR_STEPS: '10000,20000,30000,40000,60000,80000:2'    # the steps to decay lr: the downscale rate
  STEPS: 50000                              # number of steps to train
  EPOCHS: 20
  BATCH_SIZE: 2                             # batch size
  NUM_WORKER: 1                               # num_worker in dataloader

# Model parameters
ARGS:
  MAX_DISP: 192             # maximum disparity
  MODEL: 'gwcnet-c'
  GRAD_METHOD: 'detach'
  NDISP: (48, 24)           # ndisps
  DISP_INTER_R: (4, 1)      # disp_intervals_ratio
  DLOSSW: (0.5, 2.0)        # depth loss weight for different stage
  CR_BASE_CHS: (32, 32, 16) # cost regularization base channels
  USING_NS: True            # using neighbor search
  NS_SIZE: 3                # nb_size
  CROP_HEIGHT: 256          # crop height
  CROP_WIDTH: 512           # crop width

# Data augmentation
DATA_AUG:
  # Color jitter
  BRIGHT_MIN: 0.4
  BRIGHT_MAX: 1.4
  CONTRAST_MIN: 0.8
  CONTRAST_MAX: 1.2

  # Gaussian blur
  GAUSSIAN_MIN: 0.1
  GAUSSIAN_MAX: 2.0
  GAUSSIAN_KERNEL: 11